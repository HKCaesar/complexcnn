{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import deepdish as dd\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# test = dd.io.load('testcomplex.h5')\n",
    "test = dd.io.load('itest.h5')\n",
    "# ddtrain  = dd.io.load('train.h5')\n",
    "\n",
    "\n",
    "\n",
    "#TAKES COMPLEX VALUE DATA AND FIXES THE NUMPY ARRAY STRUCTURE FOR INPUT TO COMPLEXCAFFE... \n",
    "    #REAL AND IMAGINARY COEFFICIENTS AS FLOATS IN SEPARATE CHANNELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.concatenate([train['data'].real, train['data'].imag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test1 = {}\n",
    "test2 = {}\n",
    "test3 = {}\n",
    "test4 = {}\n",
    "test5 = {}\n",
    "test6 = {}\n",
    "test7 = {}\n",
    "test8 = {}\n",
    "test9 = {}\n",
    "test10 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#BREAK THE DATA UP INTO CHUNKS <2GB EACH (10 different chunks!)\n",
    "test1['data'] = test['data'][:240].astype(np.float32)\n",
    "test2['data'] = test['data'][240:240*2].astype(np.float32)\n",
    "test3['data'] = test['data'][240*2:240*3].astype(np.float32)\n",
    "test4['data'] = test['data'][240*3:240*4].astype(np.float32)\n",
    "test5['data'] = test['data'][240*4:240*5].astype(np.float32)\n",
    "test6['data'] = test['data'][240*5:240*6].astype(np.float32)\n",
    "test7['data'] = test['data'][240*6:240*7].astype(np.float32)\n",
    "test8['data'] = test['data'][240*7:240*8].astype(np.float32)\n",
    "test9['data'] = test['data'][240*8:240*9].astype(np.float32)\n",
    "test10['data'] = test['data'][240*9:].astype(np.float32)\n",
    "\n",
    "#BREAK THE label UP INTO CHUNKS <2GB EACH (10 different chunks!)\n",
    "test1['label'] = test['label'][:240].astype(np.float32)\n",
    "test2['label'] = test['label'][240:240*2].astype(np.float32)\n",
    "test3['label'] = test['label'][240*2:240*3].astype(np.float32)\n",
    "test4['label'] = test['label'][240*3:240*4].astype(np.float32)\n",
    "test5['label'] = test['label'][240*4:240*5].astype(np.float32)\n",
    "test6['label'] = test['label'][240*5:240*6].astype(np.float32)\n",
    "test7['label'] = test['label'][240*6:240*7].astype(np.float32)\n",
    "test8['label'] = test['label'][240*7:240*8].astype(np.float32)\n",
    "test9['label'] = test['label'][240*8:240*9].astype(np.float32)\n",
    "test10['label'] = test['label'][240*9:].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #save out test data:\n",
    "with h5py.File('float32/test10.h5', 'w') as ltrain:\n",
    "    ltrain.create_dataset('label', data=test10['label'])\n",
    "    ltrain.create_dataset('data', data=test10['data'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-4349c822e2b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#BREAK THE DATA UP INTO CHUNKS <1GB EACH (10 different chunks!)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m720\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m720\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m720\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m720\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m720\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m720\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m720\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "#BREAK THE DATA UP INTO CHUNKS <2GB EACH (10 different chunks!)\n",
    "train1 = train['data'][:720]\n",
    "train2 = train['data'][720:720*2]\n",
    "train3 = train['data'][720*2:720*3]\n",
    "train4 = train['data'][720*3:720*4]\n",
    "train5 = train['data'][720*4:720*5]\n",
    "train5 = train['data'][720*5:720*6]\n",
    "train6 = train['data'][720*6:720*7]\n",
    "train7 = train['data'][720*7:720*8]\n",
    "train8 = train['data'][720*8:720*9]\n",
    "train9 = train['data'][720*9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 2, 513, 101, 2)\n"
     ]
    }
   ],
   "source": [
    "# print(train['data'][:720].shape)#[:720].shape)\n",
    "# print(train2.shape)\n",
    "# print(train3.shape)\n",
    "# print(train4.shape)\n",
    "# print(train5.shape)\n",
    "# print(train6.shape)\n",
    "# print(train7.shape)\n",
    "# print(train8.shape)\n",
    "print(test9.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "(3600, 2, 513, 101)\n",
      "(3600, 2, 513, 101, 1)\n",
      "(3600, 2, 513, 101, 1)\n",
      "(3600, 2, 513, 101, 2)\n"
     ]
    }
   ],
   "source": [
    "#format data for complex caffe\n",
    "\n",
    "# train:\n",
    "print(\"TRAIN\")\n",
    "real = train['data'].real\n",
    "imag = train['data'].imag\n",
    "\n",
    "#release some memory (11.94GB)\n",
    "# %reset_selective train\n",
    "\n",
    "\n",
    "print(real.shape)\n",
    "print(np.expand_dims(real, axis=4).shape)\n",
    "print(np.expand_dims(imag, axis=4).shape)\n",
    "real = np.expand_dims(real, axis=4)\n",
    "imag = np.expand_dims(imag, axis=4)\n",
    "\n",
    "trainconcat = np.concatenate([real, imag], axis=4)\n",
    "print(trainconcat.shape)\n",
    "\n",
    "\n",
    "#release some more memory\n",
    "# %reset_selective imag\n",
    "# %reset_selective real\n",
    "\n",
    "\n",
    "#test:\n",
    "# print(\"TEST\")\n",
    "# real = test['data'].real\n",
    "# imag = test['data'].imag\n",
    "\n",
    "# print(real.shape)\n",
    "# print(np.expand_dims(real, axis=4).shape)\n",
    "# print(np.expand_dims(imag, axis=4).shape)\n",
    "# real = np.expand_dims(real, axis=4)\n",
    "# imag = np.expand_dims(imag, axis=4)\n",
    "\n",
    "# testconcat = np.concatenate([real, imag], axis=4)\n",
    "# print(testconcat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainconcat.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #save out train data:\n",
    "with h5py.File('itrain6.h5', 'w') as itrain:\n",
    "    itrain.create_dataset('label', data=train['label'][720*5:720*6])\n",
    "    itrain.create_dataset('data', data=train['data'][720*5:720*6])\n",
    "    \n",
    "#save out test data:\n",
    "# with h5py.File('itest.h5', 'w') as itest:\n",
    "#     itest.create_dataset('label', data=test['label'])\n",
    "#     itest.create_dataset('data', data=testconcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainorig = test = dd.io.load('itrain.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainorig['data'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(trainconcat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "l = train['label']\n",
    "%reset_selective train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-269eb77b41b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 2, 513, 101)\n"
     ]
    }
   ],
   "source": [
    "#check shapes\n",
    "print(test['data'].shape)\n",
    "# print(train['data'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00044531860378320892+1.1150338234861157e-06j)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['data'][0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 2, 513, 101)\n",
      "(2400, 2, 513, 101, 1)\n",
      "(2400, 2, 513, 101, 1)\n"
     ]
    }
   ],
   "source": [
    "print(real.shape)\n",
    "print(np.expand_dims(real, axis=4).shape)\n",
    "print(np.expand_dims(imag, axis=4).shape)\n",
    "real = np.expand_dims(real, axis=4)\n",
    "imag = np.expand_dims(imag, axis=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "concat = np.concatenate([real, imag], axis=4)\n",
    "#where [None,:] adds an axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 2, 513, 101, 2)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.45318604e-04,   1.11503382e-06])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat[0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#separate out real and imaginary components\n",
    "real = train['data'][:][:][:].real\n",
    "imag = train['data'][:][:][:].imag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#stack the data back into two channel representation of complex numbers\n",
    "#all numbers are dtype float64, but first is real, second is imaginary\n",
    "t = np.stack([real, imag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 7200, 2, 513, 101)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test1 = h5py.File(\"testh5py1.hdf5\", \"w\")\n",
    "# train1 = h5py.File(\"trainh5py1.hdf5\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test1.create_dataset(\"data\", data=d['data'])\n",
    "# test1.create_dataset(\"label\", data=d['label'])\n",
    "\n",
    "# train1.create_dataset(\"data\", data=test['data'])\n",
    "# train1.create_dataset(\"label\", data=test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save out train data:\n",
    "with h5py.File('trainh5py.h5', 'w') as train:\n",
    "    train.create_dataset('label', data=ddtrain['label'])\n",
    "    train.create_dataset('data', data=ddtrain['data'])\n",
    "    \n",
    "#save out test data:\n",
    "with h5py.File('train1.h5', 'w') as train1:\n",
    "    train1.create_dataset('label', data=train['label'])\n",
    "    train1.create_dataset('data', data=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = dd.io.load('float32/test6.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 2, 513, 101, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attempt = test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4+4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train1 = dd.io.load('float32/ft1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new['data'] = train1['data'][:10]\n",
    "new['label'] = train1['label'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2, 513, 101, 2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test1 = dd.io.load('float32/test1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newtest = {}\n",
    "newtest['data'] = test1['data'][:10]\n",
    "newtest['label'] = test1['label'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save out train data:\n",
    "with h5py.File('tentrain.h5', 'w') as train:\n",
    "    train.create_dataset('label', data=new['label'])\n",
    "    train.create_dataset('data', data=new['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save out train data:\n",
    "with h5py.File('tentest.h5', 'w') as testy:\n",
    "    testy.create_dataset('label', data=newtest['label'])\n",
    "    testy.create_dataset('data', data=newtest['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
